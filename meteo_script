setwd("C:/Users/emili/Desktop/Better_meteo_data/data_csv")
setwd("C:/Users/Jos√©/Desktop/better_meteo_data/better_data")

library(ggplot2)
library(tidyverse)
library(flextable)
library(patchwork)
library(RColorBrewer)
library(viridis)
library(dplyr)
library(lubridate)
library(stringr)
library(zoo)

dir()
files <- list.files(pattern = "\\.csv$")

for (f in files) {
  message("Processing: ", f)

  data <- data.table::fread(f)

  data$AAAAMM <- as.yearmon(as.character(data$AAAAMM), format = "%Y%m")
  data$year <- year(data$AAAAMM)
  data$month <- month(data$AAAAMM)

  data_cut <- data %>% select(NOM_USUEL, LAT, LON, ALTI, AAAAMM,
                              RR, TM, TX, RRAB, NBJNEIG,
                              NBJGREL, NBJORAG, NBJBROU)

  data_cut$file <- f

  out_path <- file.path("C:/Users/emili/Desktop/Better_meteo_data/data_cut", f)
  write_csv(data_cut, out_path)

  rm(data, data_cut)
  gc()
}


files <- list.files("C:/Users/emili/Desktop/Better_meteo_data/data_cut",
                    full.names = TRUE)

dir.create("C:/Users/emili/Desktop/Better_meteo_data/data_cut/old_files",
           showWarnings = FALSE)
dir.create("C:/Users/emili/Desktop/Better_meteo_data/data_cut/recent_files",
           showWarnings = FALSE)
dir.create("C:/Users/emili/Desktop/Better_meteo_data/data_cut/very_recent_files",
           showWarnings = FALSE)

for (f in files) {
  fname <- basename(f)

  if (str_detect(fname, "1949")) {
    out_path <- file.path("C:/Users/emili/Desktop/Better_meteo_data/data_cut/old_files", fname)
    file.rename(f, out_path)
  } else if (str_detect(fname, "2023")) {
    out_path <- file.path("C:/Users/emili/Desktop/Better_meteo_data/data_cut/recent_files", fname)
    file.rename(f, out_path)
  } else if (str_detect(fname, "2024")) {
    out_path <- file.path("C:/Users/emili/Desktop/Better_meteo_data/data_cut/very_recent_files", fname)
    file.rename(f, out_path)
  }
}

#### NEXT LOOP IS NOT DONE PLS DONT RUN IT ITS TRASH ####
# idk if i keep it even?
### Next loop is to delete cols with 70%+ na and rows with 60%+ na, but as i said in the other script,
### i think even with fuckass na, we can still make graphs and all bc 90% missing data still leaves
### like 3k data to work with, thats already good amount for a graph and shit.
### so i keep it for now, but we'll see what we do with it
for (f in files) {
    message("Processing: ", f)

    data <- data.table::fread(f)
  
    # Checking nas per row :
    na_summary_rows <- data %>% mutate(
        na_row = rowSums(is.na(data)),               
        tot_row = ncol(data),
        na_prop = na_row / tot_row * 100 
        )

    # Filter rows with >60% na
    na_summary_rows %>% filter(na_prop > 60)

    ## add deletion code

    # Getting na proportion per column :
    na_summary <- data %>%
    summarise(across(everything(), ~ mean(is.na(.)))) %>%
    pivot_longer(everything(), names_to = "column", values_to = "na_prop") %>%
    mutate(na_prop = na_prop * 100)

    # Filter columns with >70% na
    na_summary %>% filter(na_prop > 70)

    ## add deletion code

    ### add writing file code
    ### add cleanup code
}